{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Automatically creates categories for a set of tags using word embeddings and clustering techniques.\n",
    "\n",
    "Loads JSON data (Obtained from the api) and extracts all tags into a list. It ensures that all tags are unique and in lowercase.\n",
    "Each unique tag is tokenized into words. A Word2Vec model is trained on these tokenized tags to create vector representations of the words.\n",
    "For each tag, the code calculates a vector representation by averaging the vectors of the words in the tag using the trained model.\n",
    "Applies K-Means clustering to the tag vectors, grouping the tags into 8 clusters based on their vector similarities.\n",
    "Outputs the tags along with their corresponding cluster numbers, effectively categorizing the tags based on their semantic similarity.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "data_json = '''\n",
    "{\"data\":{\"generativeTokens\":[\n",
    "    {\"tags\":[\"AI\",\"AIartwork\",\"AIart\",\"AI art\",\"2d\",\"Paint\",\"artificial intelligence\",\"AI_TezoArt\",\"Abstract\",\"art\",\"tezosart\",\"tezosnft\",\"tezos\",\"tezosnfts\",\"nft\"],\"author\":{\"name\":\"AITezoArt\"}},\n",
    "    {\"tags\":[\"Generative Art\",\"Digital Art\",\"Child\",\"Childhood\",\"Charity\",\"Game\",\"Toy\",\"Colorful\",\"Marbles\",\"Art\",\"Contemporary\",\"RecollectionArts\",\"Nostalgic\",\"Fine Arts\",\"Interior Design\"],\"author\":{\"name\":null}},\n",
    "    {\"tags\":[\"generative\",\"animation\",\"png\",\"sliced\",\"time\"],\"author\":{\"name\":null}},\n",
    "    {\"tags\":[\"generative\",\"genart\",\"abstract\",\"p5js\",\"noise\",\"perlin\",\"randomness\",\"colors\",\"contours\",\"uniray\"],\"author\":{\"name\":\"Uniray\"}},\n",
    "    {\"tags\":[\"explosion\",\"pop art\",\"hongkongers\",\"halftone\",\"eruption\",\"upheaval\",\"tranquility\",\"forthcoming\",\"diaspora\",\"immigrate\",\"BNO\"],\"author\":{\"name\":null}},\n",
    "    {\"tags\":[\"interactive\",\"abstract\",\"cubes\",\"infinite\"],\"author\":{\"name\":null}},\n",
    "    {\"tags\":[\"onchainsummer2024\",\"webgl\",\"dreams\",\"polygons\",\"triangles\"],\"author\":{\"name\":null}},\n",
    "    {\"tags\":[\"code\",\"creative\",\"generative\",\"waves\",\"bw\",\"ferdoropeza\"],\"author\":{\"name\":null}},\n",
    "    {\"tags\":[\"deterioration art\",\"architecture\",\"nature\",\"animation\",\"japan\",\"p5js\"],\"author\":{\"name\":\"Asahamiz\"}},\n",
    "    {\"tags\":[],\"author\":{\"name\":null}},\n",
    "    {\"tags\":[\"colors\",\"art\",\"picture\",\"nft\",\"GT\",\"unsleeping\"],\"author\":{\"name\":null}},\n",
    "    {\"tags\":[\"geometric\",\"abstract\",\"art\",\"shapes\",\"colors\"],\"author\":{\"name\":null}},\n",
    "    {\"tags\":[\"art\",\"generative\",\"fxhash\",\"tezos\",\"random\",\"pattern\",\"geometry\",\"pixel\",\"color\"],\"author\":{\"name\":null}},\n",
    "    {\"tags\":[\"creative coding\",\"abstract\",\"p5js\",\"tezos\",\"xtz\",\"data\"],\"author\":{\"name\":\"aliasrubytuesday\"}},\n",
    "    {\"tags\":[\"geometric\",\"abstract\",\"art\",\"shapes\",\"colors\"],\"author\":{\"name\":\"jrcart.tez\"}},\n",
    "    {\"tags\":[\"lines\",\"javascript\",\"genart\",\"colors\"],\"author\":{\"name\":\"RosbelDev\"}},\n",
    "    {\"tags\":[],\"author\":{\"name\":null}},\n",
    "    {\"tags\":[],\"author\":{\"name\":null}},\n",
    "    {\"tags\":[\"generative art\",\"layered\",\"ai\",\"animation\",\"video\",\"symbol\",\"layers\",\"frostxhash\",\"hobo\",\"homeless\",\"disturbed\",\"florida man\",\"lost\",\"poetry\",\"rambler\",\"madman\",\"crazy\",\"amsterdam\",\"utrecht\",\"den haag\",\"haarlem\",\"arnhem\",\"netherlands\",\"city\",\"neighborhood\",\"clairvoyant\",\"prescient\",\"supernatural\",\"prophet\"],\"author\":{\"name\":\"Plastic Tolstoy\"}},\n",
    "    {\"tags\":[\"creative coding\",\"abstract\",\"p5js\",\"tezos\",\"xtz\",\"data\"],\"author\":{\"name\":\"aliasrubytuesday\"}}\n",
    "]}}\n",
    "'''\n",
    "\n",
    "data = json.loads(data_json)\n",
    "tags_list = [tag for item in data['data']['generativeTokens'] for tag in item['tags']]\n",
    "unique_tags = list(set(tags.lower() for tags in tags_list))\n",
    "\n",
    "tokenized_tags = [word_tokenize(tag) for tag in unique_tags]\n",
    "\n",
    "# Model training\n",
    "model_w2v = Word2Vec(tokenized_tags, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Creation of tag vectors using the mean of word vectors\n",
    "def tag_vector(tag):\n",
    "    words = word_tokenize(tag.lower())\n",
    "    return np.mean([model_w2v.wv[word] for word in words if word in model_w2v.wv], axis=0)\n",
    "\n",
    "tag_vectors = np.array([tag_vector(tag) for tag in unique_tags if tag_vector(tag) is not None])\n",
    "\n",
    "# Clustering using K-means\n",
    "kmeans = KMeans(n_clusters=8, random_state=42)\n",
    "kmeans.fit(tag_vectors)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "tag_clusters = {tag: label for tag, label in zip(unique_tags, labels)}\n",
    "\n",
    "for tag, cluster in tag_clusters.items():\n",
    "    print(f\"Tag: {tag} -> Cluster: {cluster}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
